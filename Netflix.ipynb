{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Netflix.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zG1MbLRE-O2ByxYktjx8_SvMN7-j1osz",
      "authorship_tag": "ABX9TyOgpWGsNILnl2aRjKKwTPAf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishdasari148/Recommender-Systems-using-Collaborative-Filtering/blob/master/Netflix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX7Nk4tUGZND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import requests\n",
        "# Please replace the url with a new api call from \"https://www.kaggle.com/netflix-inc/netflix-prize-data\" since the API call has timeout.\n",
        "url = '<use your api key here>'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "dir_name = 'drive/My Drive/Colab Notebooks/Netflix'\n",
        "open(os.path.join(dir_name, 'data' + \".\" + 'zip'), 'wb').write(r.content)\n",
        "import zipfile\n",
        "with zipfile.ZipFile('data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.join(dir_name, 'data'))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrvhLTwMGm26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "dir_name = 'drive/My Drive/Colab Notebooks/Netflix/data'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPPatowpML76",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "fd845016-18ed-49a5-fd31-1a41223bdfde"
      },
      "source": [
        "# Converting the txt files into csv files\n",
        "files = ['combined_data_1.txt','combined_data_2.txt','combined_data_3.txt','combined_data_4.txt']\n",
        "for j in files:\n",
        "    file1 = open(os.path.join(dir_name, j),\"r+\")\n",
        "    print(j + \" opened...\")\n",
        "    file2 = open(os.path.join(dir_name, j + '.csv'),\"a\")\n",
        "    for i in file1.readlines():\n",
        "        temp = re.match(\"(\\d*)[:]\", i)\n",
        "        if(temp):\n",
        "            movienumber = temp.group(1)\n",
        "        else:\n",
        "            file2.write(str(movienumber)+\",\"+i)\n",
        "    file1.close()\n",
        "    file2.close() \n",
        "    print(j + \" closed...\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "combined_data_1.txt opened...\n",
            "combined_data_1.txt closed...\n",
            "combined_data_2.txt opened...\n",
            "combined_data_2.txt closed...\n",
            "combined_data_3.txt opened...\n",
            "combined_data_3.txt closed...\n",
            "combined_data_4.txt opened...\n",
            "combined_data_4.txt closed...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC9yBe1SNcF4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "bc00bb27-6ffe-4451-ff7b-607c00f81344"
      },
      "source": [
        "movie_titles = pd.read_csv(os.path.join(dir_name, 'movie_titles.csv'), encoding = 'ISO-8859-1', header = None, names=['Movie', 'Year of Release', 'Title'], usecols=[0, 1, 2])\n",
        "movie_titles"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Movie</th>\n",
              "      <th>Year of Release</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>Dinosaur Planet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>Isle of Man TT 2004 Review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>Character</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1994.0</td>\n",
              "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>The Rise and Fall of ECW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17765</th>\n",
              "      <td>17766</td>\n",
              "      <td>2002.0</td>\n",
              "      <td>Where the Wild Things Are and Other Maurice Se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17766</th>\n",
              "      <td>17767</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>Fidel Castro: American Experience</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17767</th>\n",
              "      <td>17768</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>Epoch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17768</th>\n",
              "      <td>17769</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>The Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17769</th>\n",
              "      <td>17770</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>Alien Hunter</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17770 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Movie  ...                                              Title\n",
              "0          1  ...                                    Dinosaur Planet\n",
              "1          2  ...                         Isle of Man TT 2004 Review\n",
              "2          3  ...                                          Character\n",
              "3          4  ...                       Paula Abdul's Get Up & Dance\n",
              "4          5  ...                           The Rise and Fall of ECW\n",
              "...      ...  ...                                                ...\n",
              "17765  17766  ...  Where the Wild Things Are and Other Maurice Se...\n",
              "17766  17767  ...                  Fidel Castro: American Experience\n",
              "17767  17768  ...                                              Epoch\n",
              "17768  17769  ...                                        The Company\n",
              "17769  17770  ...                                       Alien Hunter\n",
              "\n",
              "[17770 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcEufh7-Mzdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Merge rating data with movie data\n",
        "\n",
        "# df_raw = pd.read_csv(os.path.join(dir_name, 'combined_data_1.txt.csv'), header=None, names=['Movie', 'User', 'Rating', 'Date'], usecols=[0, 1, 2, 3])\n",
        "# df_raw = df_raw.merge(movie_titles, on = ['Movie'],how = 'inner')\n",
        "# df_raw"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrbtIH7dCQGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## extracting additional features from date component\n",
        "\n",
        "# def add_datepart(df, fldname, drop=True):\n",
        "#     fld = df[fldname]\n",
        "#     if not np.issubdtype(fld.dtype, np.datetime64):\n",
        "#         df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
        "#     targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
        "#     for n in ('Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
        "#             'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start'):\n",
        "#         df[targ_pre+n] = getattr(fld.dt,n.lower())\n",
        "#     # df[targ_pre+'Elapsed'] = fld.astype(np.int64) // 10**9\n",
        "#     if drop: df.drop(fldname, axis=1, inplace=True)\n",
        "# add_datepart(df_raw,'Date')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEPCVPA11wUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## appending all the csv files of rating data into a single dataframe\n",
        "dfs = []\n",
        "for i in ['combined_data_1.txt.csv','combined_data_2.txt.csv','combined_data_3.txt.csv','combined_data_4.txt.csv']:\n",
        "    df_raw = pd.read_csv(os.path.join(dir_name, 'combined_data_1.txt.csv'), header=None, names=['Movie', 'User', 'Rating', 'Date'], usecols=[0, 1, 2, 3])\n",
        "    df_raw = df_raw[['Movie','User','Rating']]\n",
        "    dfs.append(df_raw)\n",
        "df_raw = pd.concat(dfs, ignore_index=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEEFq58H2mmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving the merged file to drive for further use.\n",
        "df_raw.to_csv(path_or_buf=os.path.join(dir_name, 'data.txt.csv'),index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR9lat9N3Nnv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "753118eb-6d96-44df-f39c-63f89f102a75"
      },
      "source": [
        "# loading the saved csv into dataframe\n",
        "df_raw = pd.read_csv(os.path.join(dir_name, 'data.txt.csv'))\n",
        "df_raw"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Movie</th>\n",
              "      <th>User</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1488844</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>822109</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>885013</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>30878</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>823519</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96215051</th>\n",
              "      <td>4499</td>\n",
              "      <td>2591364</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96215052</th>\n",
              "      <td>4499</td>\n",
              "      <td>1791000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96215053</th>\n",
              "      <td>4499</td>\n",
              "      <td>512536</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96215054</th>\n",
              "      <td>4499</td>\n",
              "      <td>988963</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96215055</th>\n",
              "      <td>4499</td>\n",
              "      <td>1704416</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96215056 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Movie     User  Rating\n",
              "0             1  1488844       3\n",
              "1             1   822109       5\n",
              "2             1   885013       4\n",
              "3             1    30878       4\n",
              "4             1   823519       3\n",
              "...         ...      ...     ...\n",
              "96215051   4499  2591364       2\n",
              "96215052   4499  1791000       2\n",
              "96215053   4499   512536       5\n",
              "96215054   4499   988963       3\n",
              "96215055   4499  1704416       3\n",
              "\n",
              "[96215056 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etbpo6QCaox5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d33a2f37-ccf4-4cd7-fb8b-7c424b5a87e8"
      },
      "source": [
        "# spliting the dataset into training_dataset(80%) and validation_dataset(20%) \n",
        "\n",
        "def is_val(x, y):\n",
        "    return x % 5 == 0\n",
        "def is_train(x, y):\n",
        "    return not is_val(x, y)\n",
        "recover = lambda x,y: y\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((df_raw['Movie'].values,df_raw['User'].values, df_raw['Rating'].values)).shuffle(10, reshuffle_each_iteration=False)\n",
        "train_dataset = dataset.enumerate().filter(is_train).map(recover).shuffle(len(df_raw)//200).batch(len(df_raw)//5000)\n",
        "validation_dataset = dataset.enumerate().filter(is_val).map(recover).shuffle(len(df_raw)//200).batch(len(df_raw)//5000)\n",
        "del dataset\n",
        "for x, y, z in train_dataset.take(1):\n",
        "    pass\n",
        "x,y,z"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(19243,), dtype=int64, numpy=array([172,  44,  28, ..., 166, 108, 118])>,\n",
              " <tf.Tensor: shape=(19243,), dtype=int64, numpy=array([2109208, 2581508, 2322592, ..., 1542006, 1691661,   69065])>,\n",
              " <tf.Tensor: shape=(19243,), dtype=int64, numpy=array([3, 5, 4, ..., 4, 3, 4])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19yTaDDfIYFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c37b10ea-9421-482e-f8fc-ee666f0d5462"
      },
      "source": [
        "class RecommenderModelDot(tf.keras.Model):\n",
        "    def __init__(self, no_of_movies, no_of_users, size_of_embeddings=100):\n",
        "        super(RecommenderModelDot, self).__init__()\n",
        "        self.size_of_embeddings = size_of_embeddings\n",
        "        self.bias = tf.random.normal([1], 0, 1, tf.float32)\n",
        "        self.embeddings_for_movies = tf.keras.layers.Embedding(no_of_movies, size_of_embeddings, embeddings_regularizer=tf.keras.regularizers.L2(l2=0.00001))\n",
        "        self.embeddings_for_users = tf.keras.layers.Embedding(no_of_users, size_of_embeddings,embeddings_regularizer=tf.keras.regularizers.L2(l2=0.00001))\n",
        "    def call(self, inputs_movies, inputs_users):\n",
        "        x = self.embeddings_for_movies(inputs_movies)\n",
        "        y = self.embeddings_for_users(inputs_users)\n",
        "        biasx, x = tf.split(x, [1, self.size_of_embeddings-1], 1)\n",
        "        biasy, y = tf.split(y, [1, self.size_of_embeddings-1], 1)\n",
        "        return tf.squeeze(tf.math.add_n([self.bias + biasx , biasy , tf.keras.backend.batch_dot(x,y)]))\n",
        "model_1 = RecommenderModelDot(17770+1, 2649429+1, 100)\n",
        "model_1(x,y)\n",
        "model_1.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"recommender_model_dot\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  1777100   \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      multiple                  264943000 \n",
            "=================================================================\n",
            "Total params: 266,720,100\n",
            "Trainable params: 266,720,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9kz6DdSOyDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "9c0bf8a3-8032-4a55-934f-12219bb28b80"
      },
      "source": [
        "class RecommenderModelNeuMF(tf.keras.Model):\n",
        "    def __init__(self, no_of_movies, no_of_users, size_of_embeddings=100):\n",
        "        super(RecommenderModelNeuMF, self).__init__()\n",
        "        self.size_of_embeddings = size_of_embeddings\n",
        "        self.j = size_of_embeddings//2\n",
        "        self.DotWeights = tf.random.normal([self.size_of_embeddings-self.j], 0, 1, tf.float32)\n",
        "        self.embeddings_for_movies = tf.keras.layers.Embedding(no_of_movies, size_of_embeddings, embeddings_regularizer=tf.keras.regularizers.L2(l2=0.00001))\n",
        "        self.embeddings_for_users = tf.keras.layers.Embedding(no_of_users, size_of_embeddings,embeddings_regularizer=tf.keras.regularizers.L2(l2=0.00001))\n",
        "        self.hidden_layer_1 = tf.keras.layers.Dense(100, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(l2=0.00001))\n",
        "        self.hidden_layer_2 = tf.keras.layers.Dense(25, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(l2=0.00001))\n",
        "        self.output_layer = tf.keras.layers.Dense(1, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.L2(l2=0.00001))\n",
        "    def call(self, inputs_movies, inputs_users):\n",
        "        x = self.embeddings_for_movies(inputs_movies)\n",
        "        y = self.embeddings_for_users(inputs_users)\n",
        "        j = self.size_of_embeddings//2\n",
        "        xMLP, xGMF = tf.split(x, [self.j, self.size_of_embeddings-self.j], 1)\n",
        "        yMLP, yGMF = tf.split(y, [self.j, self.size_of_embeddings-self.j], 1)\n",
        "        return tf.math.add(tf.math.reduce_sum(tf.math.multiply(yGMF, tf.math.multiply(self.DotWeights, xGMF)), axis=1), \n",
        "                          tf.squeeze(self.output_layer(self.hidden_layer_2(self.hidden_layer_1(tf.concat([xMLP,yMLP], axis=1))))))\n",
        "model_2 = RecommenderModelNeuMF(17770+1, 2649429+1, 100)\n",
        "model_2(x,y)\n",
        "model_2.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"recommender_model_neu_mf\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      multiple                  1777100   \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      multiple                  264943000 \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  2525      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  26        \n",
            "=================================================================\n",
            "Total params: 266,732,751\n",
            "Trainable params: 266,732,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qyen8R5nSfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.mean_squared_error\n",
        "def loss(model, x, y, z, training):\n",
        "    y_ = model(x, y, training=training)\n",
        "    return loss_object(y_true=z, y_pred=y_)\n",
        "def grad(model, x, y, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, x, y, targets, training=True)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuXZD-gcq0-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## check if the loss function, gradient and optimization step are working as intended\n",
        "\n",
        "# for x, y, z in dataset.take(10):\n",
        "#     loss_value, grads = grad(model_2, x, y, z)\n",
        "#     optimizer.apply_gradients(zip(grads, model_2.trainable_variables))\n",
        "#     print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(),loss(model_2, x, y, z, training=True).numpy()))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvBvR8TGmtSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training both the models on the given data\n",
        "train_loss_results_Dot = []\n",
        "train_loss_results_MLP = []\n",
        "validation_loss_results_Dot = []\n",
        "validation_loss_results_MLP = []\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for model in [model_1, model_2]:\n",
        "        start = time.time()\n",
        "        epoch_loss_avg_train = tf.keras.metrics.Mean()\n",
        "        epoch_loss_avg_validation = tf.keras.metrics.Mean()\n",
        "        progbar = tf.keras.utils.Progbar(1002)\n",
        "        num=0\n",
        "        for x, y, z in train_dataset:\n",
        "            num=num+1\n",
        "            progbar.update(num)\n",
        "            loss_value, grads = grad(model, x, y, z)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "            # Track progress\n",
        "            epoch_loss_avg_train.update_state(loss_value)  # Add current batch loss\n",
        "        for x, y, z in validation_dataset:\n",
        "            num=num+1\n",
        "            progbar.update(num)\n",
        "            epoch_loss_avg_validation.update_state(loss(model, x, y, z, training=False))\n",
        "        # End epoch\n",
        "        if model == model_1:\n",
        "            train_loss_results_Dot.append(epoch_loss_avg_train.result().numpy())\n",
        "            validation_loss_results_Dot.append(epoch_loss_avg_validation.result().numpy())\n",
        "        else:\n",
        "            train_loss_results_MLP.append(epoch_loss_avg_train.result().numpy())\n",
        "            validation_loss_results_MLP.append(epoch_loss_avg_validation.result().numpy())\n",
        "        end = time.time()\n",
        "        print(\"{} Epoch {:03d}: Loss: {:.3f}, Validation Loss: {:.3f}, Time Taken: {}\".format(model, epoch, epoch_loss_avg_train.result(), \n",
        "                                                                                              epoch_loss_avg_validation.result(), end-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXQMbCNUgn4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = plt.figure(figsize=(20,8))\n",
        "plt.subplot(1, 2, 1)\n",
        "train_dot, = plt.plot(range(len(train_loss_results_Dot)),train_loss_results_Dot, label='Dot')\n",
        "train_mlp, = plt.plot(range(len(train_loss_results_MLP)),train_loss_results_MLP, label='MLP')\n",
        "plt.title('training Losses')\n",
        "plt.legend(handles=[train_dot,train_mlp]);\n",
        "plt.subplot(1, 2, 2)\n",
        "val_dot, = plt.plot(range(len(validation_loss_results_Dot)),validation_loss_results_Dot, label='Dot')\n",
        "val_mlp, = plt.plot(range(len(validation_loss_results_MLP)),validation_loss_results_MLP, label='MLP')\n",
        "plt.title('Validation Losses')\n",
        "plt.legend(handles=[val_dot,val_mlp]);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}